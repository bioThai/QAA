---
title: 'Bi623: RNA-Seq Quality Assessment Assignment'
author: "Thai Nguyen"
date: "Due 9/7/2021"
output:
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: yes
header-includes:
- \usepackage{float}
- \let\origfigure\figure
- \let\endorigfigure\endfigure
- \renewenvironment{figure}[1][2] { \expandafter\origfigure\expandafter[H]} { \endorigfigure}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = "!h")

library(ggplot2)
library(tidyverse)
library(knitr) #needed to use kable to make nicer looking tables for knitted file
library(rmarkdown)


```

## Objectives
The objectives of this assignment are to use existing tools for quality assessment and adapter trimming, compare the quality assessments to those from your own software, and to demonstrate your ability to summarize other important information about this RNA-Seq data set.

### Data: 
Each of you will be working with 2 of the demultiplexed file pairs. For all steps below, process the two libraries separately. Library assignments are here: ```/projects/bgmp/shared/Bi623/QAA_data_assignments.txt```

The demultiplexed, gzipped .fastq files are here: ```/projects/bgmp/shared/2017_sequencing/demultiplexed/```

#### Do not move, copy, or unzip these data!

***
# Part 1 – Read quality score distributions


#### 1. Using ```FastQC``` via the command line on Talapas, produce plots of quality score distributions for R1 and R2 reads. Also, produce plots of the per-base N content, and comment on whether or not they are consistent with the quality score plots.

As shown in the plots below, the per-base N content plots are consistent with the per-base quality score distribution plots. The per-base N content plots have higher N content for the first few base pair positions, which corresponds with the lower q-scores for the first few base pair positions in the q-score distribution plots.

__FastQC bash script:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=fastqc_pt1_%j.out
#SBATCH --error=fastqc_pt1_%j.err

module load fastqc/0.11.5

input_dir="/projects/bgmp/shared/2017_sequencing/demultiplexed/"
dataset1_r1="21_3G_both_S15_L008_R1_001.fastq.gz"
dataset1_r2="21_3G_both_S15_L008_R2_001.fastq.gz"
dataset2_r1="4_2C_mbnl_S4_L008_R1_001.fastq.gz"
dataset2_r2="4_2C_mbnl_S4_L008_R2_001.fastq.gz"
output_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt1/fastqc_pt1_output/"

/usr/bin/time -v fastqc -t 2 ${input_dir}$dataset1_r1 ${input_dir}$dataset1_r2 -o $output_dir
/usr/bin/time -v fastqc -t 2 ${input_dir}$dataset2_r1 ${input_dir}$dataset2_r2 -o $output_dir

exit
```

![Quality score distribution for 4_2C_mbnl_S4_L008_R1.](pt1/fastqc_output/4_2C_mbnl_S4_L008_R1_001_fastqc/per_base_quality.png)

![N content for 4_2C_mbnl_S4_L008_R1.](pt1/fastqc_output/4_2C_mbnl_S4_L008_R1_001_fastqc/per_base_n_content.png)

![Quality score distribution for 4_2C_mbnl_S4_L008_R2.](pt1/fastqc_output/4_2C_mbnl_S4_L008_R2_001_fastqc/per_base_quality.png)

![N content for 4_2C_mbnl_S4_L008_R2.](pt1/fastqc_output/4_2C_mbnl_S4_L008_R2_001_fastqc/per_base_n_content.png)

![Quality score distribution for 21_3G_both_S15_L008_R1.](pt1/fastqc_output/21_3G_both_S15_L008_R1_001_fastqc/per_base_quality.png)

![N content for 21_3G_both_S15_L008_R1.](pt1/fastqc_output/21_3G_both_S15_L008_R1_001_fastqc/per_base_n_content.png)

![Quality score distribution for 21_3G_both_S15_L008_R2.](pt1/fastqc_output/21_3G_both_S15_L008_R2_001_fastqc/per_base_quality.png)

![N content for 21_3G_both_S15_L008_R2.](pt1/fastqc_output/21_3G_both_S15_L008_R2_001_fastqc/per_base_n_content.png)

#### 2. Run your quality score plotting script from your Demultiplexing assignment from Bi622. Describe how the ```FastQC``` quality score distribution plots compare to your own. If different, propose an explanation. Also, does the runtime differ? If so, why?

See below plots for Python and bash wrapper scripts. 

The FastQC qscore distribution plots show a similar trend to the plots generated by my script: lower qscores for the first few base pair positions, then mostly consistently high qscores for the rest of the base pair positions.

The runtime of the FastQC commands was also much faster than the runtime for my qscore plotting scripts. It took FastQC a total of about 2 mins 8 secs to process all 4 input files, while my script took a total of about 18 mins to process all 4 input files. 

One reason for this difference in runtime could be that FastQC is written in Java by professionals, while my script is written in Python, which may not handle memory as efficiently.


![Mean quality score distribution from Python script for 4_2C_mbnl_S4_L008_R1.](pt1/plot_4_2C_mbnl_S4_L008_R1_001.fastq.gz.png)

![Mean quality score distribution from Python script for 4_2C_mbnl_S4_L008_R2.](pt1/plot_4_2C_mbnl_S4_L008_R2_001.fastq.gz.png)

![Mean quality score distribution from Python script for 21_3G_both_S15_L008_R1.](pt1/plot_21_3G_both_S15_L008_R1_001.fastq.gz.png)

![Mean quality score distribution from Python script for 21_3G_both_S15_L008_R2.](pt1/plot_21_3G_both_S15_L008_R2_001.fastq.gz.png)

__Quality score plotting python script:__

```bash
#!/bin/python
import argparse
import gzip     #needed to read g-zipped files
import matplotlib.pyplot as plt
import Bioinfo

def get_args():
    '''Defines/sets possible command line arguments for script'''
    parser = argparse.ArgumentParser("A program to process FASTQ data, get average quality score for each read position, and plot distribution")
    parser.add_argument("-f", nargs="+", help="specifies input FASTQ filename(s)", type=str, required=True)
    parser.add_argument("-o", help="specifies output file prefix", type=str, required=True)
    return parser.parse_args()

def parse_file(in_filename: str, out_file_prefix: str):
    '''Open gzipped FASTQ file, put all qscores in file into arrays to track qscores for each nucleotide position.'''
    # local variables
    line_num: int = 0   #keep track of what line number of input file you're on
    read_num: int = 0   #keep track of number of records/reads in input file
    nuc_pos: int = 0    #keep track of nucleotide position
    converted_phred: int = 0
    sum_qscores_list: list = []     #keep track of the running total of qscores for each nucleotide position
    mean_qscores_list: list = []    #holds the mean qscore for each nucleotide position
    output_fname: str = "means_" + out_file_prefix + ".tsv"
    plot_name: str = "plot_" + out_file_prefix + ".png"

    with gzip.open(in_filename, 'rt') as input_file, open(output_fname, 'w') as output_file:
        for line in input_file:
            line_num += 1
            line = line.strip()
            if line_num % 4 == 0:   #grab the qscore line in filename
                nuc_pos = 0
                for char in line:
                    converted_phred = Bioinfo.convert_phred(char)
                    #if the sum_qscores_list doesn't yet have an element for each read position in the file:
                    if len(sum_qscores_list) != len(line):
                        sum_qscores_list.append(converted_phred)
                    else:
                        sum_qscores_list[nuc_pos] += converted_phred
                    nuc_pos += 1
                read_num += 1   #once whole qscore line is read, increment the read number    
        mean_qscores_list = [sum_qscore / read_num for sum_qscore in sum_qscores_list]    #divide each element in sum_qscores_list by the number of reads in the file to get the avg qscore for each nucleotide position. Put each of these avg scores into a mean_qscore_list.    
    
        #write the mean qscore for each nucleotide position into an output file
        output_file.write("Position\tMean\n")
        for i in range(len(mean_qscores_list)):
            output_file.write(str(i) + "\t" + str(mean_qscores_list[i]) + "\n")
    
    #plot mean qscore distribution
    plt.bar(range(len(mean_qscores_list)), mean_qscores_list)
    plt.title("Mean Quality Score for all Nucleotide Positions")
    plt.xlabel("Nucleotide Position")
    plt.ylabel("Mean Quality Score")
    plt.savefig(plot_name)

def main():
    '''Main function, drives the order of execution for script'''
    # local variables
    args = get_args()
    output_file_prefix = args.o

    for input_filename in args.f:
        parse_file(input_filename, output_file_prefix)

if __name__ == "__main__":
    main()
```

__Wrapper scripts for generating quality score distribution plots:__

read_qscores_f1_r1_wrapper.sh

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=16:00:00
#SBATCH --output=f1_r1_read_qscores_wrapper_%j.out
#SBATCH --error=f1_r1_read_qscores_wrapper_%j.err

conda activate bgmp_py39
script_file="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt1/read_qscores.py"
input_dir="/projects/bgmp/shared/2017_sequencing/demultiplexed/"
input_file="21_3G_both_S15_L008_R1_001.fastq.gz"
output_file_prefix=$input_file

/usr/bin/time -v python $script_file -f ${input_dir}$input_file -o $output_file_prefix

exit
```

read_qscores_f1_r2_wrapper.sh

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=16:00:00
#SBATCH --output=f1_r2_read_qscores_wrapper_%j.out
#SBATCH --error=f1_r2_read_qscores_wrapper_%j.err

conda activate bgmp_py39
script_file="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt1/read_qscores.py"
input_dir="/projects/bgmp/shared/2017_sequencing/demultiplexed/"
input_file="21_3G_both_S15_L008_R2_001.fastq.gz"
output_file_prefix=$input_file

/usr/bin/time -v python $script_file -f ${input_dir}$input_file -o $output_file_prefix

exit
```

read_qscores_f2_r1_wrapper.sh

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=16:00:00
#SBATCH --output=f2_r1_read_qscores_wrapper_%j.out
#SBATCH --error=f2_r1_read_qscores_wrapper_%j.err

conda activate bgmp_py39
script_file="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt1/read_qscores.py"
input_dir="/projects/bgmp/shared/2017_sequencing/demultiplexed/"
input_file="4_2C_mbnl_S4_L008_R1_001.fastq.gz"
output_file_prefix=$input_file

/usr/bin/time -v python $script_file -f ${input_dir}$input_file -o $output_file_prefix

exit
```

read_qscores_f2_r2_wrapper.sh

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=16:00:00
#SBATCH --output=f2_r2_read_qscores_wrapper_%j.out
#SBATCH --error=f2_r2_read_qscores_wrapper_%j.err

conda activate bgmp_py39
script_file="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt1/read_qscores.py"
input_dir="/projects/bgmp/shared/2017_sequencing/demultiplexed/"
input_file="4_2C_mbnl_S4_L008_R2_001.fastq.gz"
output_file_prefix=$input_file

/usr/bin/time -v python $script_file -f ${input_dir}$input_file -o $output_file_prefix

exit
```


#### 3. Comment on the overall data quality of your two libraries.

The overall data quality of the two libraries is high (average qscores > 38 except for the first few base pair positions), with the read 2 (R2) file for each library having slightly lower qscores on average.


***
# Part 2 – Adapter trimming comparison


#### 4. Create a new conda environment called ```QAA``` and install ```cutadapt``` and ```Trimmomatic```. Google around if you need a refresher on how to create conda environments. Make sure you check your installations with:

  * ```cutadapt --version``` (should be 3.4)
  * ```trimmomatic -version``` (should be 0.39)

Commands on Talapas:

```
conda create --name QAA python=3.9
conda activate QAA
conda install cutadapt
conda install Trimmomatic
```

#### 5. Using ```cutadapt```, properly trim adapter sequences from your assigned files. Be sure to read how to use ```cutadapt```. Use default settings. What proportion of reads (both forward and reverse) were trimmed?

For the 21_3G_both_S15_L008 dataset:

* Adapters trimmed from Read 1: 613,874 (6.6% of read pairs)
* Adapters trimeed from Read 2: 679,275 (7.4% of read pairs)

For the 4_2C_mbnl_S4_L008 dataset:

* Adapters trimmed from Read 1: 570,274 (6.2% of read pairs)
* Adapters trimeed from Read 2: 637,307 (6.9% of read pairs)

__Cutadapt script:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=cutadapt_%j.out
#SBATCH --error=cutadapt_%j.err

conda activate QAA

input_dir="/projects/bgmp/shared/2017_sequencing/demultiplexed/"
dataset1_r1="21_3G_both_S15_L008_R1_001.fastq.gz"
dataset1_r2="21_3G_both_S15_L008_R2_001.fastq.gz"
dataset2_r1="4_2C_mbnl_S4_L008_R1_001.fastq.gz"
dataset2_r2="4_2C_mbnl_S4_L008_R2_001.fastq.gz"
r1_adapter="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"
r2_adapter="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
output_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/cutadapt_output/"
output_file1="${output_dir}adapter_trimmed_${dataset1_r1}"
output_file2="${output_dir}adapter_trimmed_${dataset1_r2}"
output_file3="${output_dir}adapter_trimmed_${dataset2_r1}"
output_file4="${output_dir}adapter_trimmed_${dataset2_r2}"

# cut read 1 and read 2 adapter sequences from the dataset 1 paired-end files
/usr/bin/time -v cutadapt -a $r1_adapter -A $r2_adapter \
-o $output_file1 -p $output_file2 \
${input_dir}$dataset1_r1 ${input_dir}$dataset1_r2

# cut read 1 and read 2 adapter sequences from the dataset 2 paired-end files
/usr/bin/time -v cutadapt -a $r1_adapter -A $r2_adapter \
-o $output_file3 -p $output_file4 \
${input_dir}$dataset2_r1 ${input_dir}$dataset2_r2

exit
```
 
__Sanity check: Use your Unix skills to search for the adapter sequences in your datasets and confirm the expected sequence orientations. Report the commands you used, the reasoning behind them, and how you confirmed the adapter sequences.__

Running a ```zcat $fastq_gz_file | grep --color='auto' $adapter_seq``` command for the R1 adapter in the R1 read files shows that the R1 adapter tends to be present closer to the 3' end of the read sequence. The same trend occurs when running a similar command to find R2 adapters in the R2 read files.

In addition, as shown below, the R1 adapter sequence is present in forward orientation (5'- AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -3') for 66732 of the 21_3G_both_S15_L008_R1 reads and 51173 of the 4_2C_mbnl_S4_L008_R1 reads. The R2 adapter sequence is present in forward orientation (5'- AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -3') for 67707 of the 21_3G_both_S15_L008_R1 reads and 51593 of the 4_2C_mbnl_S4_L008_R1 reads.

However, the reverse orientation (5'- ACTGACCTCAAGTCTGCACACGAGAAGGCTAGA -3') of the R1 adapter sequence was not present in any of the R1 reads in either dataset. In addition, the reverse orientation (5'- TGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA -3') of the R2 adapter sequence was not present in any of the R2 reads in either dataset. Thus, the R1 adapter sequence is 5'- AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -3' and the R2 adapter sequence is 5'- AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -3'.

Checking for the presence of the R2 adapter sequence in the R1 reads (and vice versa) also yielded counts of zero, indicating that the R1 adapters were correctly applied to the R1 reads and the R2 adapters were correctly applied to the R2 reads.

__Bash script to count how many times each potential orientation (forward or reverse) of the adapter sequences occurs in the read sequences:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --time=10:00:00
#SBATCH --output=confirm_%j.out
#SBATCH --error=confirm_%j.err

set1_r1="/projects/bgmp/shared/2017_sequencing/demultiplexed/21_3G_both_S15_L008_R1_001.fastq.gz"
set1_r2="/projects/bgmp/shared/2017_sequencing/demultiplexed/21_3G_both_S15_L008_R2_001.fastq.gz"
set2_r1="/projects/bgmp/shared/2017_sequencing/demultiplexed/4_2C_mbnl_S4_L008_R1_001.fastq.gz"
set2_r2="/projects/bgmp/shared/2017_sequencing/demultiplexed/4_2C_mbnl_S4_L008_R2_001.fastq.gz"
adapter_r1="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"
adapter_r1_rev="ACTGACCTCAAGTCTGCACACGAGAAGGCTAGA"
adapter_r2="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
adapter_r2_rev="TGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA"

# search for R1 adapter forward sequence in R1 files
echo "21_3G_both_S15_L008_R1 forward R1 adapters"
zcat $set1_r1 | grep -c $adapter_r1
echo "4_2C_mbnl_S4_L008_R1 forward R1 adapters"
zcat $set2_r1 | grep -c $adapter_r1

# search for R2 adapter forward sequence in R2 files
echo "21_3G_both_S15_L008_R2 forward R2 adapters"
zcat $set1_r2 | grep -c $adapter_r2
echo "4_2C_mbnl_S4_L008_R2 forward R2 adapters"
zcat $set2_r2 | grep -c $adapter_r2

# search for reverse of R1 adapter sequence in R1 files
echo "21_3G_both_S15_L008_R1 rev R1 adapters"
zcat $set1_r1 | grep -c $adapter_r1_rev
echo "4_2C_mbnl_S4_L008_R1 rev R1 adapters"
zcat $set2_r1 | grep -c $adapter_r1_rev

# search for reverse of R2 adapter sequence in R2 files
echo "21_3G_both_S15_L008_R2 rev R2 adapters"
zcat $set1_r2 | grep -c $adapter_r2_rev
echo "4_2C_mbnl_S4_L008_R2 rev R2 adapters"
zcat $set2_r2 | grep -c $adapter_r2_rev

# search for R2 adapter forward sequence in R1 files
echo "21_3G_both_S15_L008_R1, count of R2 forward adapters"
zcat $set1_r1 | grep -c $adapter_r2
echo "4_2C_mbnl_S4_L008_R1 count of R2 forward adapters"
zcat $set2_r1 | grep -c $adapter_r2

# search for R1 adapter forward sequence in R2 files
echo "21_3G_both_S15_L008_R2 count of R1 forward adapters"
zcat $set1_r2 | grep -c $adapter_r1
echo "4_2C_mbnl_S4_L008_R2 count of R1 forward adapters"
zcat $set2_r2 | grep -c $adapter_r1

```

__Output of running the above script:__

```
21_3G_both_S15_L008_R1 forward R1 adapters
66732
4_2C_mbnl_S4_L008_R1 forward R1 adapters
51173
21_3G_both_S15_L008_R2 forward R2 adapters
67707
4_2C_mbnl_S4_L008_R2 forward R2 adapters
51593
21_3G_both_S15_L008_R1 rev R1 adapters
0
4_2C_mbnl_S4_L008_R1 rev R1 adapters
0
21_3G_both_S15_L008_R2 rev R2 adapters
0
4_2C_mbnl_S4_L008_R2 rev R2 adapters
0
21_3G_both_S15_L008_R1, count of R2 forward adapters
0
4_2C_mbnl_S4_L008_R1 count of R2 forward adapters
0
21_3G_both_S15_L008_R2 count of R1 forward adapters
0
4_2C_mbnl_S4_L008_R2 count of R1 forward adapters
0
```


#### 6. Use ```Trimmomatic``` to quality trim your reads. Specify the following, in this order:

  * __LEADING: quality of 3__
  * __TRAILING: quality of 3__
  * __SLIDING WINDOW: window size of 5 and required quality of 15__
  * __MINLENGTH: 35 bases__

  __Be sure to output compressed files and clear out any intermediate files.__

__Trimmomatic script:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=trimmomatic_%j.out
#SBATCH --error=trimmomatic_%j.err

conda activate QAA

# if trimmomatic.jar path is unknown, run:
# find /projects/bgmp/tnguye14/miniconda3/envs/QAA/ -name "trimmomatic.jar" -print

trimmomatic_jar_path="/projects/bgmp/tnguye14/miniconda3/envs/QAA/share/trimmomatic-0.39-2/trimmomatic.jar"
input_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/cutadapt_output/"
output_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/trimmomatic_output/"
adapter_trimmed_dataset1_R1="${input_dir}adapter_trimmed_21_3G_both_S15_L008_R1_001.fastq.gz"
adapter_trimmed_dataset1_R2="${input_dir}adapter_trimmed_21_3G_both_S15_L008_R2_001.fastq.gz"
adapter_trimmed_dataset2_R1="${input_dir}adapter_trimmed_4_2C_mbnl_S4_L008_R1_001.fastq.gz"
adapter_trimmed_dataset2_R2="${input_dir}adapter_trimmed_4_2C_mbnl_S4_L008_R2_001.fastq.gz"
output_dataset1_template="${output_dir}q_and_adapter_trimmed_21_3G_both_S15_L008.fastq.gz"
output_dataset2_template="${output_dir}q_and_adapter_trimmed_4_2C_mbnl_S4_L008.fastq.gz"
dataset1_trimlog="${output_dir}trimlog_21_3G_both_S15_L008.txt"
dataset2_trimlog="${output_dir}trimlog_4_2C_mbnl_S4_L008.txt"

#run trimmomatic in paired-end (PE) mode on each dataset
/usr/bin/time -v java -jar $trimmomatic_jar_path \
PE \
$adapter_trimmed_dataset1_R1 $adapter_trimmed_dataset1_R2 \
-baseout $output_dataset1_template \
-trimlog $dataset1_trimlog \
-threads 4 \
LEADING:3 \
TRAILING:3 \
SLIDINGWINDOW:5:15 \
MINLEN:35

/usr/bin/time -v java -jar $trimmomatic_jar_path \
PE \
$adapter_trimmed_dataset2_R1 $adapter_trimmed_dataset2_R2 \
-baseout $output_dataset2_template \
-trimlog $dataset2_trimlog \
-threads 4 \
LEADING:3 \
TRAILING:3 \
SLIDINGWINDOW:5:15 \
MINLEN:35

exit
```

#### 7. Plot the trimmed read length distributions for both R1 and R2 reads (on the same plot). You can produce 2 different plots for your 2 different RNA-seq samples. There are a number of ways you could possibly do this. One useful thing your plot should show, for example, is whether R1s are trimmed more extensively than R2s, or vice versa. Comment on whether you expect R1s and R2s to be adapter-trimmed at different rates.

R2 reads are expected to be trimmed at higher rates than R1 reads. This may be due to degradation of R2 libraries and/or sequencing reagents because they've been on the sequencer flowcell for a longer period of time.

```{r}
dataset1_r1_df = read.delim("read_len_freqs_21_3G_both_S15_L008_R1.txt", header = TRUE, sep = " ")
dataset1_r2_df = read.delim("read_len_freqs_21_3G_both_S15_L008_R2.txt", header = TRUE, sep = " ")
dataset2_r1_df = read.delim("read_len_freqs_4_2C_mbnl_S4_L008_R1.txt", header = TRUE, sep = " ")
dataset2_r2_df = read.delim("read_len_freqs_4_2C_mbnl_S4_L008_R2.txt", header = TRUE, sep = " ")

#paged_table(dataset1_r1_df)
#paged_table(dataset1_r2_df)
#paged_table(dataset2_r1_df)
#paged_table(dataset2_r2_df)

dataset1_joined_df = full_join(dataset1_r1_df, dataset1_r2_df, by = "Trimmed_read_length", suffix = c("_R1", "_R2"))
dataset2_joined_df = full_join(dataset2_r1_df, dataset2_r2_df, by = "Trimmed_read_length", suffix = c("_R1", "_R2"))

#reorder columns in joined datasets for aesthetic reasons 
dataset1_joined_df = dataset1_joined_df[ , c("Trimmed_read_length", "Frequency_R1", "Frequency_R2")]
dataset2_joined_df = dataset2_joined_df[ , c("Trimmed_read_length", "Frequency_R1", "Frequency_R2")]

#plot R1 and R2 frequencies for dataset1
dataset1_joined_df %>%
  pivot_longer(cols = c("Frequency_R1", "Frequency_R2"), names_to = "Read_file", values_to = "Frequency") %>%
  mutate(Read_file = substr(Read_file, 11, 12)) %>%
  ggplot(aes(x = Trimmed_read_length, y = Frequency, fill = Read_file)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_y_log10() +
  labs(title = "Distribution of Quality-Trimmed Read Lengths for 21_3G_both_S15_L008", x = "Trimmed Read Lengths (nt)", y = "Frequency of Read Length", fill = "Read File")

#plot R1 and R2 frequencies for dataset2
dataset2_joined_df %>%
  pivot_longer(cols = c("Frequency_R1", "Frequency_R2"), names_to = "Read_file", values_to = "Frequency") %>%
  mutate(Read_file = substr(Read_file, 11, 12)) %>%
  ggplot(aes(x = Trimmed_read_length, y = Frequency, fill = Read_file)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_y_log10() +
  labs(title = "Distribution of Quality-Trimmed Read Lengths for 4_2C_mbnl_S4_L008", x = "Trimmed Read Lengths (nt)", y = "Frequency of Read Length", fill = "Read File")

#display joined datasets
kable(dataset1_joined_df, caption = "Trimmed read length distribution for R1 and R2 reads in 21_3G_both_S15_L008")
kable(dataset2_joined_df, caption = "Trimmed read length distribution for R1 and R2 reads in 4_2C_mbnl_S4_L008")

```


***
# Part 3 – Alignment and strand-specificity


#### 8. Install sofware. In your QAA environment, use conda to install:
    - star
    - numpy
    - pysam
    - matplotlib

    Then ```pip install HTSeq```

Commands:

```
conda activate QAA
conda install star -c bioconda
conda install numpy pysam matplotlib
pip install HTSeq
```

#### 9. Find publicly available mouse genome fasta files (Ensemble release 104) and generate an alignment database from them. Align the reads to your mouse genomic database using a splice-aware aligner. Use the settings specified in PS8 from Bi621.

  * __Hint - you will need to use gene models to perform splice-aware alignment, see PS8 from Bi621.__
    
Mouse genome used: __Mus musculus__

Mouse genome and GTF files used to generate alignment reference database to which the 4_2C_mbnl_S4_L008 and 21_3G_both_S15_L008 datasets will be aligned:

* Mus_musculus.GRCm39.dna.primary_assembly.fa.gz
* Mus_musculus.GRCm39.104.gtf.gz

__Script for building alignment reference database with STAR:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=build_star_db%j.out
#SBATCH --error=build_star_db%j.err

conda activate QAA

my_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/"
genome_dir="${my_dir}Mus_musculus.GRCm39.dna.ens104.STAR_2.7.9a/"
genome_fasta_file_gz="${my_dir}Mus_musculus.GRCm39.dna.primary_assembly.fa.gz"
GTF_file_gz="${my_dir}Mus_musculus.GRCm39.104.gtf.gz"
genome_fasta_file_unzipped="${my_dir}Mus_musculus.GRCm39.dna.primary_assembly.fa"
GTF_file_unzipped="${my_dir}Mus_musculus.GRCm39.104.gtf"

#unzip the files to build STAR database
/usr/bin/time -v gunzip $genome_fasta_file_gz $GTF_file_gz

/usr/bin/time -v STAR --runThreadN 8 \
--runMode genomeGenerate \
--genomeDir $genome_dir \
--genomeFastaFiles $genome_fasta_file_unzipped \
--sjdbGTFfile $GTF_file_unzipped

#zip the unzipped files back up to save storage space
/usr/bin/time -v gzip $genome_fasta_file_unzipped $GTF_file_unzipped

exit
```

__Script for performing STAR alignments of adapter- and quality-trimmed R1 and R2 reads from 4_2C_mbnl_S4_L008:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --time=10:00:00
#SBATCH --output=star_align1_%j.out
#SBATCH --error=star_align1_%j.err

conda activate QAA

my_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/"
input_read_file1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/trimmomatic_output/q_and_adapter_trimmed_4_2C_mbnl_S4_L008_1P.fastq.gz"
input_read_file2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/trimmomatic_output/q_and_adapter_trimmed_4_2C_mbnl_S4_L008_2P.fastq.gz"
genome_dir="${my_dir}Mus_musculus.GRCm39.dna.ens104.STAR_2.7.9a"
output_filename_prefix="${my_dir}star_align_output/star_4_2C_mbnl_S4_L008_"

/usr/bin/time -v STAR --runThreadN 8 \
--runMode alignReads \
--outFilterMultimapNmax 3 \
--outSAMunmapped Within KeepPairs \
--alignIntronMax 1000000 --alignMatesGapMax 1000000 \
--readFilesCommand zcat \
--readFilesIn $input_read_file1 $input_read_file2 \
--genomeDir $genome_dir \
--outFileNamePrefix $output_filename_prefix

exit
```

__Script for performing STAR alignments of adapter- and quality-trimmed R1 and R2 reads from 21_3G_both_S15_L008:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --time=10:00:00
#SBATCH --output=star_align2_%j.out
#SBATCH --error=star_align2_%j.err

conda activate QAA

my_dir="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/"
input_read_file1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/trimmomatic_output/q_and_adapter_trimmed_21_3G_both_S15_L008_1P.fastq.gz"
input_read_file2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt2/trimmomatic_output/q_and_adapter_trimmed_21_3G_both_S15_L008_2P.fastq.gz"
genome_dir="${my_dir}Mus_musculus.GRCm39.dna.ens104.STAR_2.7.9a"
output_filename_prefix="${my_dir}star_align_output/star_21_3G_both_S15_L008_"

/usr/bin/time -v STAR --runThreadN 8 \
--runMode alignReads \
--outFilterMultimapNmax 3 \
--outSAMunmapped Within KeepPairs \
--alignIntronMax 1000000 --alignMatesGapMax 1000000 \
--readFilesCommand zcat \
--readFilesIn $input_read_file1 $input_read_file2 \
--genomeDir $genome_dir \
--outFileNamePrefix $output_filename_prefix

exit
```

#### 10. Using your script from PS8 in Bi621, report the number of mapped and unmapped reads from each of your 2 sam files. Make sure that your script is looking at the bitwise flag to determine if reads are primary or secondary mapping (update your script if necessary).

For ```star_4_2C_mbnl_S4_L008_Aligned.out.sam``` file:

* Mapped count: 17172669
* Unmapped count: 788093

For ```star_21_3G_both_S15_L008_Aligned.out.sam``` file:

* Mapped count: 17061136
* Unmapped count: 645494

Python script for counting number of mapped and unmapped reads from SAM files:

```bash
#!/bin/python
import argparse

def get_args():
    '''Defines/sets possible command line arguments for script'''
    parser = argparse.ArgumentParser("A program to parse SAM file and count number of mapped reads")
    parser.add_argument("-f", nargs="+", help="Specifies input filename(s). Must be SAM files.", type=str, required=True)
    return parser.parse_args()

def get_mapped_unmapped_counts(filename: str):
    '''Get mapped and unmapped read counts from an input SAM file for reads that are not from a secondary alignment (not duplicates).'''
    #local variables
    mapped_count: int = 0
    unmapped_count: int = 0
    line_tokens: list = []
    bitwise_flag: int = 0
    mapped_count: int = 0
    unmapped_count: int = 0

    print(filename)

    with open(filename, 'r') as fh:
        for line in fh:
            if line.startswith("@"):
                continue    #go to next loop iteration and read next line in file
            else:
                line_tokens = line.split("\t")
                bitwise_flag = int(line_tokens[1])
                
                #if read is not unmapped (read is mapped) AND read is not from a secondary alignment (read is not a duplicate)
                if ((bitwise_flag & 4) != 4) and ((bitwise_flag & 256) != 256): #if read is mapped
                    #mapped = True
                    mapped_count += 1
                else:   #if read is unmapped
                    if ((bitwise_flag & 256) != 256): #if read is not from a secondary alignment (read is not a duplicate)
                        unmapped_count += 1

    print("Mapped count:", mapped_count)
    print("Unmapped count:", unmapped_count)   
                
def main():
    '''Main function, drives the order of execution for script'''
    #local variables
    args = get_args()
    file_list: list = args.f

    for file in file_list:
        get_mapped_unmapped_counts(file)

if __name__ == "__main__":
    main()
```

Bash wrapper script for running the above SAM-parsing Python script in SLURM on Talapas:

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=parse_SAM_%j.out
#SBATCH --error=parse_SAM_%j.err

conda activate QAA

script_file="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/parse_SAM_redux.py"
sam_file_1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/star_align_output/star_4_2C_mbnl_S4_L008_Aligned.out.sam"
sam_file_2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/star_align_output/star_21_3G_both_S15_L008_Aligned.out.sam"

/usr/bin/time -v python $script_file -f $sam_file_1 $sam_file_2

exit
```


#### 11. Count reads that map to features using htseq-count. You should run htseq-count twice: once with ```--stranded=yes``` and again with ```--stranded=no```. Use default parameters otherwise.

See below for first 20 lines and last 5 lines of htseq-count output for stranded and unstranded runs. 

See pt3/ directory in QAA repository on Github for full htseq-count output files (55000+ lines each) from stranded and unstranded runs. Note that column 2 in each output file holds counts for the STAR-aligned 4_2C_mbnl_S4_L008 SAM file, and column 3 in each output file holds counts for the STAR-aligned 21_3G_both_S15_L008 SAM file.

```{r}
stranded_tibble = read_tsv("pt3/htseq_stranded_16214476.out", 
                           col_names = c("Gene/Feature", "Read count (4_2C_mbnl_S4_L008)", "Read count (21_3G_both_S15_L008)"),
                           show_col_types = FALSE)

unstranded_tibble = read_tsv("pt3/htseq_unstranded_16214641.out",
                             col_names = c("Gene/Feature", "Read count (4_2C_mbnl_S4_L008)", "Read count (21_3G_both_S15_L008)"),
                             show_col_types = FALSE)

kable(head(stranded_tibble, n = 20), caption = "Htseq-count output (stranded setting), first 20 lines")
kable(tail(stranded_tibble, n = 5), caption = "Htseq-count output (stranded setting), last 5 lines")

kable(head(unstranded_tibble, n = 20), caption = "Htseq-count output (unstranded setting), first 20 lines")
kable(tail(unstranded_tibble, n = 5), caption = "Htseq-count output (stranded setting), last 5 lines")

```


__Bash script for htseq-count (stranded setting):__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=htseq_stranded_%j.out
#SBATCH --error=htseq_stranded_%j.err

conda activate QAA

#star_aligned_file1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/star_align_output/star_4_2C_mbnl_S4_L008_Aligned.out.sam"
#star_aligned_file2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/star_align_output/star_21_3G_both_S15_L008_Aligned.out.sam"

star_aligned_file1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/sorted_star_4_2C_mbnl_S4_L008_Aligned.out.sam"
star_aligned_file2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/sorted_star_21_3G_both_S15_L008_Aligned.out.sam"
ref_genome_gtf_zipped="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/Mus_musculus.GRCm39.104.gtf.gz"
ref_genome_gtf_unzipped="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/Mus_musculus.GRCm39.104.gtf"

/usr/bin/time -v gunzip $ref_genome_gtf_zipped

/usr/bin/time -v htseq-count --stranded=yes \
$star_aligned_file1 $star_aligned_file2 \
$ref_genome_gtf_unzipped

/usr/bin/time -v gzip $ref_genome_gtf_unzipped

exit
```

__Bash script for htseq-count (unstranded setting):__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=htseq_unstranded_%j.out
#SBATCH --error=htseq_unstranded_%j.err

conda activate QAA

# star_aligned_file1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/star_align_output/star_4_2C_mbnl_S4_L008_Aligned.out.sam"
# star_aligned_file2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/star_align_output/star_21_3G_both_S15_L008_Aligned.out.sam"

star_aligned_file1="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/sorted_star_4_2C_mbnl_S4_L008_Aligned.out.sam"
star_aligned_file2="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/sorted_star_21_3G_both_S15_L008_Aligned.out.sam"
ref_genome_gtf_zipped="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/Mus_musculus.GRCm39.104.gtf.gz"
ref_genome_gtf_unzipped="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/Mus_musculus.GRCm39.104.gtf"

/usr/bin/time -v gunzip $ref_genome_gtf_zipped

/usr/bin/time -v htseq-count --stranded=no \
$star_aligned_file1 $star_aligned_file2 \
$ref_genome_gtf_unzipped

/usr/bin/time -v gzip $ref_genome_gtf_unzipped

exit
```

#### 12. Demonstrate convincingly whether or not the data are from “strand-specific” RNA-Seq libraries. Include any comands/scripts used. Briefly describe your evidence, using quantitative statements (e.g. "I propose that these data are/are not strand-specific, because X% of the reads are y, as opposed to z.").

  * __Hint - recall ICA4 from Bi621.__

The data looks like it's from unstranded RNA-seq libraries because the mapped read percentages for unstranded htseq output (78.4411% for 4_2C_mbnl_S4_L008, 78.831% for 21_3G_both_S15_L008) are much higher than for stranded htseq output (3.8868% for 4_2C_mbnl_S4_L008, 3.69892% for 21_3G_both_S15_L008). See below for mapped and unmapped read percentages for each dataset, as well as the bash script used to generate this data.

__Mapped and unmapped counts and percentages for each dataset:__

```
***** 4_2C_mbnl_S4_L008 *****
* MAPPED COUNTS *
Stranded:  349049
Unstranded:  7044313
* UNMAPPED COUNTS *
Stranded:  8631332
Unstranded:  1936068
* PERCENT MAPPED *
Stranded:  3.8868
Unstranded:  78.4411

***** 21_3G_both_S15_L008 *****
* MAPPED COUNTS *
Stranded:  327477
Unstranded:  6979158
* UNMAPPED COUNTS *
Stranded:  8525838
Unstranded:  1874157
* PERCENT MAPPED *
Stranded:  3.69892
Unstranded:  78.831
```

__Bash script used to generate mapped and unmapped count and percentage data from each dataset:__

```bash
#!/bin/bash

#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --cpus-per-task=8
#SBATCH --time=10:00:00
#SBATCH --output=get_mapped_stats_%j.out
#SBATCH --error=get_mapped_stats_%j.err

conda activate QAA

htseq_stranded_output="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/htseq_stranded_16213781.out"
htseq_unstranded_output="/projects/bgmp/tnguye14/bioinfo/Bi623/QAA/pt3/htseq_unstranded_16213805.out"

#get mapped counts for 4_2C_mbnl_S4_L008 from stranded and unstranded htseqcount outputs
echo "***** 4_2C_mbnl_S4_L008 *****"
echo "* MAPPED COUNTS *"
awk '$1~/^ENS/{sum+=$2} END {print "Stranded: ", sum}' $htseq_stranded_output
awk '$1~/^ENS/{sum+=$2} END {print "Unstranded: ", sum}' $htseq_unstranded_output

echo "* UNMAPPED COUNTS *"
awk '$1!~/^ENS/{sum+=$2} END {print "Stranded: ", sum}' $htseq_stranded_output
awk '$1!~/^ENS/{sum+=$2} END {print "Unstranded: ", sum}' $htseq_unstranded_output

echo "* PERCENT MAPPED *"
awk '$1~/^ENS/{mappedreads+=$2} {totalreads+=$2} END {print "Stranded: ", (mappedreads/totalreads)*100}' $htseq_stranded_output
awk '$1~/^ENS/{mappedreads+=$2} {totalreads+=$2} END {print "Unstranded: ", (mappedreads/totalreads)*100}' $htseq_unstranded_output

#get mapped counts for 21_3G_both_S15_L008 from stranded and unstranded htseqcount outputs
echo "***** 21_3G_both_S15_L008 *****"
echo "* MAPPED COUNTS *"
awk '$1~/^ENS/{sum+=$3} END {print "Stranded: ", sum}' $htseq_stranded_output
awk '$1~/^ENS/{sum+=$3} END {print "Unstranded: ", sum}' $htseq_unstranded_output

echo "* UNMAPPED COUNTS *"
awk '$1!~/^ENS/{sum+=$3} END {print "Stranded: ", sum}' $htseq_stranded_output
awk '$1!~/^ENS/{sum+=$3} END {print "Unstranded: ", sum}' $htseq_unstranded_output

echo "* PERCENT MAPPED *"
awk '$1~/^ENS/{mappedreads+=$3} {totalreads+=$3} END {print "Stranded: ", (mappedreads/totalreads)*100}' $htseq_stranded_output
awk '$1~/^ENS/{mappedreads+=$3} {totalreads+=$3} END {print "Unstranded: ", (mappedreads/totalreads)*100}' $htseq_unstranded_output

exit
```

